{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRJdOhJtggrL",
        "colab_type": "text"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [Your-Name?]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K492lcNPggrP",
        "colab_type": "text"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTrlnYsmggrQ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxuGSw7jggrR",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Yyu0W3ggrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "9f0db5c5-fa09-4ad0-f6c8-6aa264cc1596"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MIOx5DrggrY",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1W0KhEbggrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7668ce29-c3df-44be-8314-8df0fe186ba5"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "  varr=[]\n",
        "  for i in y:\n",
        "    arr = numpy.zeros(num_class,dtype=int)\n",
        "    arr[i] = 1\n",
        "    varr.append(arr)\n",
        "  return numpy.array(varr)\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[1])\n",
        "print(y_train_vec[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[9]\n",
            "[0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4QVG5IEggre",
        "colab_type": "text"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKDnuknKggrf",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reRZxcONggrf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4aeea125-b19e-4526-e72f-fcf8fcc55708"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7jbvAOLggri",
        "colab_type": "text"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3uBnmIDggrj",
        "colab_type": "text"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix0KCfysggrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c5b9bd9-662a-4382-90a4-b91d73d43489"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer = regularizers.l2(weight_decay),input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer = regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_regularizer = regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_regularizer = regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_regularizer = regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_regularizer = regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,362\n",
            "Trainable params: 551,466\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFH4680NZCzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odH0E_17ggrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-3 \n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate,decay=1E-6),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbvKzLcHggrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "44f4b03f-ba8d-4761-87ea-2806c9135cb9"
      },
      "source": [
        "\n",
        "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=64),steps_per_epoch=1000, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7015 - acc: 0.8280 - val_loss: 0.7429 - val_acc: 0.8155\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6943 - acc: 0.8296 - val_loss: 0.6594 - val_acc: 0.8490\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6955 - acc: 0.8305 - val_loss: 0.8047 - val_acc: 0.8121\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6871 - acc: 0.8330 - val_loss: 0.6514 - val_acc: 0.8559\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6927 - acc: 0.8300 - val_loss: 0.6680 - val_acc: 0.8489\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6872 - acc: 0.8318 - val_loss: 0.6137 - val_acc: 0.8546\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6814 - acc: 0.8336 - val_loss: 0.7764 - val_acc: 0.8463\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6814 - acc: 0.8331 - val_loss: 0.6068 - val_acc: 0.8670\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6861 - acc: 0.8317 - val_loss: 0.7208 - val_acc: 0.8404\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6825 - acc: 0.8326 - val_loss: 0.7170 - val_acc: 0.8446\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6841 - acc: 0.8343 - val_loss: 0.6619 - val_acc: 0.8469\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6840 - acc: 0.8343 - val_loss: 0.6533 - val_acc: 0.8505\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6875 - acc: 0.8337 - val_loss: 0.6722 - val_acc: 0.8347\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6749 - acc: 0.8369 - val_loss: 0.7236 - val_acc: 0.8358\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6838 - acc: 0.8327 - val_loss: 0.7098 - val_acc: 0.8383\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6882 - acc: 0.8346 - val_loss: 0.6700 - val_acc: 0.8554\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6815 - acc: 0.8349 - val_loss: 0.7267 - val_acc: 0.8359\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6819 - acc: 0.8337 - val_loss: 0.8193 - val_acc: 0.8264\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6873 - acc: 0.8335 - val_loss: 0.6654 - val_acc: 0.8422\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.6873 - acc: 0.8309 - val_loss: 0.7081 - val_acc: 0.8204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWDocexTggrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8e783c33-4ce5-442a-8655-60adaa7880c2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwjAMwwiLCYRhGIYRFhMIwzAMIyz/H2b5bxN1Bd3qAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F0lNY_4ggrv",
        "colab_type": "text"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBgRvt3pzP-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN8jR8Npggrw",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsCh7EcHggrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate,decay=1E-6),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFWcFHMhggrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "d705672c-56c8-4e8b-8c2a-f293e607093c"
      },
      "source": [
        "\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train_vec, batch_size=64),steps_per_epoch=1000, epochs=20)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.7048 - acc: 0.8293\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.7015 - acc: 0.8297\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7024 - acc: 0.8293\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7008 - acc: 0.8294\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.7048 - acc: 0.8268\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7052 - acc: 0.8278\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.7048 - acc: 0.8291\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7020 - acc: 0.8279\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6949 - acc: 0.8302\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6924 - acc: 0.8330\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7107 - acc: 0.8260\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7015 - acc: 0.8304\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7079 - acc: 0.8279\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7064 - acc: 0.8274\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7022 - acc: 0.8298\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7082 - acc: 0.8274\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7051 - acc: 0.8298\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7098 - acc: 0.8267\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.6991 - acc: 0.8310\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.7084 - acc: 0.8278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq-ThcqMggr3",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY8PXydWggr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8cb1b8f3-72ec-44b2-bef0-42942c6d6f6f"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 153us/step\n",
            "loss = 0.6778691120147705\n",
            "accuracy = 0.8357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-70Cavdvggr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}